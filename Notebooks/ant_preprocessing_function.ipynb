{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from decouple import config\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from authenticate_service_account import main\n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import category_encoders as ce\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from scipy.stats import zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = main()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM skyscanner-insights-343713.Itinerary_Scoring.training_set_80pct_ODs\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "\n",
    "results = query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_data = results.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_data.to_csv('../raw_data/skyscanner_data_171223', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = gcp_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_preprocessing(raw_data, columns_to_process, target_creation_function, target,\n",
    "                        box_cox_columns=False, yeo_johnson_columns=False, min_max_scaling=False, log_transform_columns=False,\n",
    "                        od_encoding=False, operator_encoding=False,\n",
    "                        target_func_param1=None, target_func_param2=None, target_func_param3=None):\n",
    "    \"\"\"\n",
    "    This functions completes all feature engineering, target creation and scaling\n",
    "    RETURNS: updated dataframe and a Class that holds all the scalers\n",
    "\n",
    "    Notes:\n",
    "    - It will only return columns in columns_to_process and the target\n",
    "    \"\"\"\n",
    "\n",
    "    #DATA CLEANING\n",
    "\n",
    "    # All int64 columns need to be float64, or some functions don't work. e.g zscore\n",
    "    for column in raw_data.select_dtypes(include=['int64']).columns:\n",
    "        raw_data[column] = raw_data[column].astype('float64')\n",
    "\n",
    "    #FEATURE ENGINEERING SECTION\n",
    "\n",
    "    # This creates a column to identify OD's\n",
    "    raw_data['OD'] = raw_data['OriginCty'] + raw_data['DestinationCty']\n",
    "\n",
    "    # This calculates the total layover time with ratio\n",
    "    raw_data['total_layover_time'] = raw_data['DurationMin'] - raw_data['Total_Flight_Duration']\n",
    "    raw_data['total_layover_time_ratio'] =raw_data['total_layover_time'] /raw_data['DurationMin']\n",
    "\n",
    "    # This calculates the difference between total distance traveled and 'straight line' distance\n",
    "    raw_data['extra_travel_distance'] = raw_data['Total_Flight_Distance'] - raw_data['TravelDistanceKm']\n",
    "    raw_data['extra_travel_distance_ratio'] =  raw_data['Total_Flight_Distance'] / raw_data['TravelDistanceKm']\n",
    "\n",
    "    # This drops all rows with neg layover time\n",
    "    data_engineered = drop_neg_layover_time(raw_data)\n",
    "\n",
    "    # Create the target\n",
    "    processed_data = target_creation_function(data_engineered, target_func_param1, target_func_param2, target_func_param3)\n",
    "\n",
    "    # Seperating target so encoders dont store a df shape that is larger than real-world data\n",
    "    # This is so encoders do not expect the extra column when running on new data, which will not have a target\n",
    "    y = processed_data[target]\n",
    "\n",
    "    model_data = processed_data.drop(columns=[target])\n",
    "\n",
    "    #BINARY ENCODING\n",
    "    # Binary encoding origin and destination\n",
    "    if od_encoding:\n",
    "        o_encoder = ce.BinaryEncoder()\n",
    "        origin_apt_encoded = o_encoder.fit_transform(model_data['OriginApt'])\n",
    "        columns_to_process.extend(origin_apt_encoded.columns.to_list())\n",
    "\n",
    "        d_encoder = ce.BinaryEncoder()\n",
    "        destination_apt_encoded = d_encoder.fit_transform(model_data['DestinationApt'])\n",
    "        columns_to_process.extend(destination_apt_encoded.columns.to_list())\n",
    "\n",
    "        #Concatinating newly encoded columns\n",
    "        origin_binary = pd.concat([model_data, origin_apt_encoded], axis=1)\n",
    "        dest_binary = pd.concat([origin_binary, destination_apt_encoded], axis=1)\n",
    "    else:\n",
    "        o_encoder = None\n",
    "        d_encoder = None\n",
    "        dest_binary = model_data.copy()\n",
    "\n",
    "    # Binary encoding Operator IATA'\n",
    "    if operator_encoding:\n",
    "        seg_0_encoder = ce.BinaryEncoder()\n",
    "        seg_0_binary = seg_0_encoder.fit_transform(model_data['Seg_0_OperatingCarrierIATA'])\n",
    "        columns_to_process.extend(seg_0_binary.columns.to_list())\n",
    "\n",
    "        seg_1_encoder = ce.BinaryEncoder()\n",
    "        seg_1_binary = seg_1_encoder.fit_transform(model_data['Seg_1_OperatingCarrierIATA'])\n",
    "        columns_to_process.extend(seg_1_binary.columns.to_list())\n",
    "\n",
    "        seg_2_encoder = ce.BinaryEncoder()\n",
    "        seg_2_binary = seg_2_encoder.fit_transform(model_data['Seg_2_OperatingCarrierIATA'])\n",
    "        columns_to_process.extend(seg_2_binary.columns.to_list())\n",
    "\n",
    "        seg_3_encoder = ce.BinaryEncoder()\n",
    "        seg_3_binary = seg_3_encoder.fit_transform(model_data['Seg_3_OperatingCarrierIATA'])\n",
    "        columns_to_process.extend(seg_3_binary.columns.to_list())\n",
    "\n",
    "        #Concatinating newly encoded columns\n",
    "        seg0_bin = pd.concat([dest_binary, seg_0_binary], axis=1)\n",
    "        seg1_bin = pd.concat([seg0_bin, seg_1_binary], axis=1)\n",
    "        seg2_bin = pd.concat([seg1_bin, seg_2_binary], axis=1)\n",
    "        all_binary = pd.concat([seg2_bin, seg_3_binary], axis=1)\n",
    "    else:\n",
    "        seg_0_encoder = None\n",
    "        seg_1_encoder = None\n",
    "        seg_2_encoder = None\n",
    "        seg_3_encoder = None\n",
    "        all_binary = dest_binary.copy()\n",
    "\n",
    "    all_binary = all_binary[columns_to_process]\n",
    "\n",
    "    #SCALING\n",
    "    # Box cox\n",
    "\n",
    "    # Dictionary to store best_lambda per column for new data processing\n",
    "    box_lambdas = {}\n",
    "\n",
    "    if box_cox_columns:\n",
    "        for col in box_cox_columns:\n",
    "            all_binary[col], box_lambda = stats.boxcox(all_binary[col])\n",
    "            box_lambdas[col] = box_lambda\n",
    "\n",
    "    # Yeo-johnson\n",
    "    # Dictionary to store best_lambda per column for new data processing\n",
    "    yeo_lambdas = {}\n",
    "\n",
    "    if yeo_johnson_columns:\n",
    "        for col in yeo_johnson_columns:\n",
    "            all_binary[col], yeo_lambda = stats.yeojohnson(all_binary[col])\n",
    "            yeo_lambdas[col] = yeo_lambda\n",
    "\n",
    "    # Log transformations\n",
    "    if log_transform_columns:\n",
    "        for column in log_transform_columns:\n",
    "            all_binary.loc[:, column] = np.log1p(model_data[column])\n",
    "\n",
    "    #Min max scaling\n",
    "    # Dictionary to store min max scaler per column for new data processing\n",
    "    min_max_scalers = {}\n",
    "\n",
    "    if min_max_scaling:\n",
    "        for col in min_max_scaling:\n",
    "            minmax_scaler = MinMaxScaler()\n",
    "            all_binary[col] = minmax_scaler.fit_transform(all_binary[[col]])\n",
    "            min_max_scalers[col] = minmax_scaler\n",
    "\n",
    "    if 'dayofweek' in columns_to_process:\n",
    "        # Cyclical encoding\n",
    "        all_binary['sin_day'] = np.sin(2 * np.pi * all_binary['dayofweek'] / 7)\n",
    "        all_binary['cos_day'] = np.cos(2 * np.pi * all_binary['dayofweek'] / 7)\n",
    "\n",
    "        all_binary.drop(columns='dayofweek', inplace=True)\n",
    "\n",
    "    if 'SelfTransfer' in columns_to_process:\n",
    "        #Inversing the importance of SelfTransfer, so Non Self Transfer is seen as better by the model\n",
    "        all_binary['SelfTransfer'] = all_binary['SelfTransfer'].apply(convert_bool_to_num)\n",
    "\n",
    "    #STORING SCALERS\n",
    "    class PreprocessScalers:\n",
    "        def __init__(self, o_encoder, d_encoder, box_lambdas, yeo_lambdas, min_max_scalers,seg_0_encoder, seg_1_encoder, seg_2_encoder, seg_3_encoder):\n",
    "                self.o_encoder = o_encoder\n",
    "                self.d_encoder = d_encoder\n",
    "                self.box_lambda = box_lambdas\n",
    "                self.yeo_lambda = yeo_lambdas\n",
    "                self.minmax_scaler = min_max_scalers\n",
    "                self.seg_0_encoder = seg_0_encoder\n",
    "                self.seg_1_encoder = seg_1_encoder\n",
    "                self.seg_2_encoder = seg_2_encoder\n",
    "                self.seg_3_encoder = seg_3_encoder\n",
    "\n",
    "    scalers = PreprocessScalers(o_encoder, d_encoder, box_lambdas, yeo_lambdas, min_max_scalers,seg_0_encoder, seg_1_encoder, seg_2_encoder, seg_3_encoder)\n",
    "\n",
    "    #Adding y into dataset\n",
    "    all_binary[target] = y\n",
    "\n",
    "    # Returning dataframe and scalers\n",
    "    return all_binary, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_raw_data = raw_data[:5000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Stops','DurationMin', 'total_layover_time_ratio', 'OriginApt', 'DestinationApt',\n",
    "            'Total_Flight_Distance','extra_travel_distance_ratio', 'dayofweek',\n",
    "            'TravelDistanceKm', 'PricePerPax', 'SelfTransfer']\n",
    "\n",
    "box_cox_columns = ['DurationMin', 'TravelDistanceKm', 'PricePerPax']\n",
    "\n",
    "yeo_johnson_columns = ['total_layover_time_ratio', 'Total_Flight_Distance', 'extra_travel_distance_ratio']\n",
    "\n",
    "min_max_scaling = ['Stops']\n",
    "\n",
    "log_transorm_cols = ['total_layover_time_ratio', 'Total_Flight_Distance', 'extra_travel_distance_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, scal = all_preprocessing(smaller_raw_data, columns, scale_itin_redirects, 'Score_Z_score_0_50',\n",
    "                  min_max_scaling=min_max_scaling, log_transform_columns=log_transorm_cols,\n",
    "                  od_encoding=True, operator_encoding=False,\n",
    "                  target_func_param1='ItineraryRedirects', target_func_param2=0, target_func_param3=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stops</th>\n",
       "      <th>DurationMin</th>\n",
       "      <th>total_layover_time_ratio</th>\n",
       "      <th>OriginApt</th>\n",
       "      <th>DestinationApt</th>\n",
       "      <th>Total_Flight_Distance</th>\n",
       "      <th>extra_travel_distance_ratio</th>\n",
       "      <th>TravelDistanceKm</th>\n",
       "      <th>PricePerPax</th>\n",
       "      <th>SelfTransfer</th>\n",
       "      <th>...</th>\n",
       "      <th>DestinationApt_2</th>\n",
       "      <th>DestinationApt_3</th>\n",
       "      <th>DestinationApt_4</th>\n",
       "      <th>DestinationApt_5</th>\n",
       "      <th>DestinationApt_6</th>\n",
       "      <th>DestinationApt_7</th>\n",
       "      <th>DestinationApt_8</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>Score_Z_score_0_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TLV</td>\n",
       "      <td>PRG</td>\n",
       "      <td>7.877018</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2635.0</td>\n",
       "      <td>183.202500</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>7.498985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TLV</td>\n",
       "      <td>PRG</td>\n",
       "      <td>7.877018</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2635.0</td>\n",
       "      <td>162.930000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>6.400767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TLV</td>\n",
       "      <td>PRG</td>\n",
       "      <td>7.877018</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2635.0</td>\n",
       "      <td>136.458333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>18.481165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TLV</td>\n",
       "      <td>RHO</td>\n",
       "      <td>6.678342</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>794.0</td>\n",
       "      <td>168.915000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>19.484019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TLV</td>\n",
       "      <td>RHO</td>\n",
       "      <td>6.678342</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>794.0</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>6.133944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>555.0</td>\n",
       "      <td>0.532217</td>\n",
       "      <td>TRN</td>\n",
       "      <td>AMS</td>\n",
       "      <td>7.034388</td>\n",
       "      <td>0.869747</td>\n",
       "      <td>818.0</td>\n",
       "      <td>97.290000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>21.427186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TRN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>6.439350</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>625.0</td>\n",
       "      <td>33.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>9.952808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TRN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>6.439350</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>625.0</td>\n",
       "      <td>37.065000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>5.217688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TRN</td>\n",
       "      <td>BCN</td>\n",
       "      <td>6.439350</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>625.0</td>\n",
       "      <td>50.275000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>5.217688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TRN</td>\n",
       "      <td>CDG</td>\n",
       "      <td>6.352629</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>573.0</td>\n",
       "      <td>220.020000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>6.783918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4997 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Stops  DurationMin  total_layover_time_ratio OriginApt  \\\n",
       "0     0.000000        240.0                  0.000000       TLV   \n",
       "1     0.000000        245.0                  0.000000       TLV   \n",
       "2     0.000000        250.0                  0.000000       TLV   \n",
       "3     0.000000        100.0                  0.000000       TLV   \n",
       "4     0.000000        100.0                  0.000000       TLV   \n",
       "...        ...          ...                       ...       ...   \n",
       "4995  0.333333        555.0                  0.532217       TRN   \n",
       "4996  0.000000         85.0                  0.000000       TRN   \n",
       "4997  0.000000         90.0                  0.000000       TRN   \n",
       "4998  0.000000         90.0                  0.000000       TRN   \n",
       "4999  0.000000         80.0                  0.000000       TRN   \n",
       "\n",
       "     DestinationApt  Total_Flight_Distance  extra_travel_distance_ratio  \\\n",
       "0               PRG               7.877018                     0.693147   \n",
       "1               PRG               7.877018                     0.693147   \n",
       "2               PRG               7.877018                     0.693147   \n",
       "3               RHO               6.678342                     0.693147   \n",
       "4               RHO               6.678342                     0.693147   \n",
       "...             ...                    ...                          ...   \n",
       "4995            AMS               7.034388                     0.869747   \n",
       "4996            BCN               6.439350                     0.693147   \n",
       "4997            BCN               6.439350                     0.693147   \n",
       "4998            BCN               6.439350                     0.693147   \n",
       "4999            CDG               6.352629                     0.693147   \n",
       "\n",
       "      TravelDistanceKm  PricePerPax  SelfTransfer  ...  DestinationApt_2  \\\n",
       "0               2635.0   183.202500             1  ...                 0   \n",
       "1               2635.0   162.930000             1  ...                 0   \n",
       "2               2635.0   136.458333             1  ...                 0   \n",
       "3                794.0   168.915000             1  ...                 0   \n",
       "4                794.0   172.500000             1  ...                 0   \n",
       "...                ...          ...           ...  ...               ...   \n",
       "4995             818.0    97.290000             1  ...                 0   \n",
       "4996             625.0    33.975000             1  ...                 0   \n",
       "4997             625.0    37.065000             1  ...                 0   \n",
       "4998             625.0    50.275000             1  ...                 0   \n",
       "4999             573.0   220.020000             1  ...                 0   \n",
       "\n",
       "      DestinationApt_3  DestinationApt_4  DestinationApt_5  DestinationApt_6  \\\n",
       "0                    0                 0                 0                 0   \n",
       "1                    0                 0                 0                 0   \n",
       "2                    0                 0                 0                 0   \n",
       "3                    0                 0                 0                 0   \n",
       "4                    0                 0                 0                 0   \n",
       "...                ...               ...               ...               ...   \n",
       "4995                 0                 0                 1                 1   \n",
       "4996                 1                 0                 1                 0   \n",
       "4997                 1                 0                 1                 0   \n",
       "4998                 1                 0                 1                 0   \n",
       "4999                 1                 0                 1                 1   \n",
       "\n",
       "      DestinationApt_7  DestinationApt_8   sin_day   cos_day  \\\n",
       "0                    0                 1 -0.974928 -0.222521   \n",
       "1                    0                 1 -0.974928 -0.222521   \n",
       "2                    0                 1 -0.433884 -0.900969   \n",
       "3                    1                 0 -0.433884 -0.900969   \n",
       "4                    1                 0  0.433884 -0.900969   \n",
       "...                ...               ...       ...       ...   \n",
       "4995                 1                 0  0.781831  0.623490   \n",
       "4996                 0                 1 -0.781831  0.623490   \n",
       "4997                 0                 1 -0.433884 -0.900969   \n",
       "4998                 0                 1 -0.974928 -0.222521   \n",
       "4999                 1                 0  0.781831  0.623490   \n",
       "\n",
       "      Score_Z_score_0_50  \n",
       "0               7.498985  \n",
       "1               6.400767  \n",
       "2              18.481165  \n",
       "3              19.484019  \n",
       "4               6.133944  \n",
       "...                  ...  \n",
       "4995           21.427186  \n",
       "4996            9.952808  \n",
       "4997            5.217688  \n",
       "4998            5.217688  \n",
       "4999            6.783918  \n",
       "\n",
       "[4997 rows x 29 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "dohop_data = pd.read_csv('../raw_data/OptiFlyAi_testset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flights</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>cnx_airport</th>\n",
       "      <th>flight_time</th>\n",
       "      <th>connection_time</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>bkgs_with_no_content</th>\n",
       "      <th>pax</th>\n",
       "      <th>bookings</th>\n",
       "      <th>booked_fare</th>\n",
       "      <th>total_distance</th>\n",
       "      <th>direct_distance</th>\n",
       "      <th>itinerary_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U27151, U23903</td>\n",
       "      <td>BCN</td>\n",
       "      <td>PRG</td>\n",
       "      <td>MXP</td>\n",
       "      <td>190</td>\n",
       "      <td>145</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47.681727</td>\n",
       "      <td>1419.022</td>\n",
       "      <td>1387.702</td>\n",
       "      <td>169.888494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U24706, U24743</td>\n",
       "      <td>TLS</td>\n",
       "      <td>FCO</td>\n",
       "      <td>NTE</td>\n",
       "      <td>200</td>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130.410688</td>\n",
       "      <td>1714.360</td>\n",
       "      <td>924.274</td>\n",
       "      <td>115.483231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U23810, U23929</td>\n",
       "      <td>CDG</td>\n",
       "      <td>RAK</td>\n",
       "      <td>MXP</td>\n",
       "      <td>290</td>\n",
       "      <td>310</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.172184</td>\n",
       "      <td>2796.943</td>\n",
       "      <td>2134.007</td>\n",
       "      <td>114.013625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TO3539, TO4630</td>\n",
       "      <td>CHQ</td>\n",
       "      <td>MAD</td>\n",
       "      <td>ORY</td>\n",
       "      <td>350</td>\n",
       "      <td>490</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.201097</td>\n",
       "      <td>3362.800</td>\n",
       "      <td>2476.722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W94498, U22325</td>\n",
       "      <td>KEF</td>\n",
       "      <td>BCN</td>\n",
       "      <td>LTN</td>\n",
       "      <td>310</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.447482</td>\n",
       "      <td>3050.737</td>\n",
       "      <td>2966.249</td>\n",
       "      <td>66.966718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018918</th>\n",
       "      <td>AV4888, AV192</td>\n",
       "      <td>AXM</td>\n",
       "      <td>SJO</td>\n",
       "      <td>BOG</td>\n",
       "      <td>200</td>\n",
       "      <td>765</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1437.405</td>\n",
       "      <td>1115.362</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018919</th>\n",
       "      <td>AV61, AV5228</td>\n",
       "      <td>PTY</td>\n",
       "      <td>CUC</td>\n",
       "      <td>BOG</td>\n",
       "      <td>170</td>\n",
       "      <td>1075</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1156.722</td>\n",
       "      <td>771.364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018920</th>\n",
       "      <td>HA5393, HA183</td>\n",
       "      <td>NRT</td>\n",
       "      <td>LIH</td>\n",
       "      <td>HNL</td>\n",
       "      <td>445</td>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6314.110</td>\n",
       "      <td>5986.291</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018921</th>\n",
       "      <td>TO4613, TO4756</td>\n",
       "      <td>AGP</td>\n",
       "      <td>BCN</td>\n",
       "      <td>ORY</td>\n",
       "      <td>255</td>\n",
       "      <td>1010</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2359.038</td>\n",
       "      <td>732.107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018922</th>\n",
       "      <td>HA335, HA22</td>\n",
       "      <td>OGG</td>\n",
       "      <td>SEA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>389</td>\n",
       "      <td>1261</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4468.388</td>\n",
       "      <td>4248.358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018923 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                flights origin destination cnx_airport  flight_time  \\\n",
       "0        U27151, U23903    BCN         PRG         MXP          190   \n",
       "1        U24706, U24743    TLS         FCO         NTE          200   \n",
       "2        U23810, U23929    CDG         RAK         MXP          290   \n",
       "3        TO3539, TO4630    CHQ         MAD         ORY          350   \n",
       "4        W94498, U22325    KEF         BCN         LTN          310   \n",
       "...                 ...    ...         ...         ...          ...   \n",
       "1018918   AV4888, AV192    AXM         SJO         BOG          200   \n",
       "1018919    AV61, AV5228    PTY         CUC         BOG          170   \n",
       "1018920   HA5393, HA183    NRT         LIH         HNL          445   \n",
       "1018921  TO4613, TO4756    AGP         BCN         ORY          255   \n",
       "1018922     HA335, HA22    OGG         SEA         HNL          389   \n",
       "\n",
       "         connection_time  dayofweek  bkgs_with_no_content  pax  bookings  \\\n",
       "0                    145          7                 False  6.0       6.0   \n",
       "1                    210          2                 False  7.0       5.0   \n",
       "2                    310          7                  True  7.0       5.0   \n",
       "3                    490          6                  True  4.0       4.0   \n",
       "4                    175          2                  True  4.0       4.0   \n",
       "...                  ...        ...                   ...  ...       ...   \n",
       "1018918              765          2                 False  NaN       NaN   \n",
       "1018919             1075          2                 False  NaN       NaN   \n",
       "1018920             1400          5                 False  NaN       NaN   \n",
       "1018921             1010          5                 False  NaN       NaN   \n",
       "1018922             1261          2                 False  NaN       NaN   \n",
       "\n",
       "         booked_fare  total_distance  direct_distance  itinerary_fare  \n",
       "0          47.681727        1419.022         1387.702      169.888494  \n",
       "1         130.410688        1714.360          924.274      115.483231  \n",
       "2          92.172184        2796.943         2134.007      114.013625  \n",
       "3         155.201097        3362.800         2476.722             NaN  \n",
       "4          81.447482        3050.737         2966.249       66.966718  \n",
       "...              ...             ...              ...             ...  \n",
       "1018918          NaN        1437.405         1115.362             NaN  \n",
       "1018919          NaN        1156.722          771.364             NaN  \n",
       "1018920          NaN        6314.110         5986.291             NaN  \n",
       "1018921          NaN        2359.038          732.107             NaN  \n",
       "1018922          NaN        4468.388         4248.358             NaN  \n",
       "\n",
       "[1018923 rows x 14 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dohop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flights</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>cnx_airport</th>\n",
       "      <th>flight_time</th>\n",
       "      <th>connection_time</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>bkgs_with_no_content</th>\n",
       "      <th>pax</th>\n",
       "      <th>bookings</th>\n",
       "      <th>booked_fare</th>\n",
       "      <th>total_distance</th>\n",
       "      <th>direct_distance</th>\n",
       "      <th>itinerary_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U27151, U23903</td>\n",
       "      <td>BCN</td>\n",
       "      <td>PRG</td>\n",
       "      <td>MXP</td>\n",
       "      <td>190</td>\n",
       "      <td>145</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47.681727</td>\n",
       "      <td>1419.022</td>\n",
       "      <td>1387.702</td>\n",
       "      <td>169.888494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U24706, U24743</td>\n",
       "      <td>TLS</td>\n",
       "      <td>FCO</td>\n",
       "      <td>NTE</td>\n",
       "      <td>200</td>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130.410688</td>\n",
       "      <td>1714.360</td>\n",
       "      <td>924.274</td>\n",
       "      <td>115.483231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U23810, U23929</td>\n",
       "      <td>CDG</td>\n",
       "      <td>RAK</td>\n",
       "      <td>MXP</td>\n",
       "      <td>290</td>\n",
       "      <td>310</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.172184</td>\n",
       "      <td>2796.943</td>\n",
       "      <td>2134.007</td>\n",
       "      <td>114.013625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TO3539, TO4630</td>\n",
       "      <td>CHQ</td>\n",
       "      <td>MAD</td>\n",
       "      <td>ORY</td>\n",
       "      <td>350</td>\n",
       "      <td>490</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.201097</td>\n",
       "      <td>3362.800</td>\n",
       "      <td>2476.722</td>\n",
       "      <td>155.201097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W94498, U22325</td>\n",
       "      <td>KEF</td>\n",
       "      <td>BCN</td>\n",
       "      <td>LTN</td>\n",
       "      <td>310</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>81.447482</td>\n",
       "      <td>3050.737</td>\n",
       "      <td>2966.249</td>\n",
       "      <td>66.966718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018918</th>\n",
       "      <td>AV4888, AV192</td>\n",
       "      <td>AXM</td>\n",
       "      <td>SJO</td>\n",
       "      <td>BOG</td>\n",
       "      <td>200</td>\n",
       "      <td>765</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1437.405</td>\n",
       "      <td>1115.362</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018919</th>\n",
       "      <td>AV61, AV5228</td>\n",
       "      <td>PTY</td>\n",
       "      <td>CUC</td>\n",
       "      <td>BOG</td>\n",
       "      <td>170</td>\n",
       "      <td>1075</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1156.722</td>\n",
       "      <td>771.364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018920</th>\n",
       "      <td>HA5393, HA183</td>\n",
       "      <td>NRT</td>\n",
       "      <td>LIH</td>\n",
       "      <td>HNL</td>\n",
       "      <td>445</td>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6314.110</td>\n",
       "      <td>5986.291</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018921</th>\n",
       "      <td>TO4613, TO4756</td>\n",
       "      <td>AGP</td>\n",
       "      <td>BCN</td>\n",
       "      <td>ORY</td>\n",
       "      <td>255</td>\n",
       "      <td>1010</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2359.038</td>\n",
       "      <td>732.107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018922</th>\n",
       "      <td>HA335, HA22</td>\n",
       "      <td>OGG</td>\n",
       "      <td>SEA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>389</td>\n",
       "      <td>1261</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4468.388</td>\n",
       "      <td>4248.358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018923 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                flights origin destination cnx_airport  flight_time  \\\n",
       "0        U27151, U23903    BCN         PRG         MXP          190   \n",
       "1        U24706, U24743    TLS         FCO         NTE          200   \n",
       "2        U23810, U23929    CDG         RAK         MXP          290   \n",
       "3        TO3539, TO4630    CHQ         MAD         ORY          350   \n",
       "4        W94498, U22325    KEF         BCN         LTN          310   \n",
       "...                 ...    ...         ...         ...          ...   \n",
       "1018918   AV4888, AV192    AXM         SJO         BOG          200   \n",
       "1018919    AV61, AV5228    PTY         CUC         BOG          170   \n",
       "1018920   HA5393, HA183    NRT         LIH         HNL          445   \n",
       "1018921  TO4613, TO4756    AGP         BCN         ORY          255   \n",
       "1018922     HA335, HA22    OGG         SEA         HNL          389   \n",
       "\n",
       "         connection_time  dayofweek  bkgs_with_no_content  pax  bookings  \\\n",
       "0                    145          7                 False  6.0       6.0   \n",
       "1                    210          2                 False  7.0       5.0   \n",
       "2                    310          7                  True  7.0       5.0   \n",
       "3                    490          6                  True  4.0       4.0   \n",
       "4                    175          2                  True  4.0       4.0   \n",
       "...                  ...        ...                   ...  ...       ...   \n",
       "1018918              765          2                 False  NaN       NaN   \n",
       "1018919             1075          2                 False  NaN       NaN   \n",
       "1018920             1400          5                 False  NaN       NaN   \n",
       "1018921             1010          5                 False  NaN       NaN   \n",
       "1018922             1261          2                 False  NaN       NaN   \n",
       "\n",
       "         booked_fare  total_distance  direct_distance  itinerary_fare  \n",
       "0          47.681727        1419.022         1387.702      169.888494  \n",
       "1         130.410688        1714.360          924.274      115.483231  \n",
       "2          92.172184        2796.943         2134.007      114.013625  \n",
       "3         155.201097        3362.800         2476.722      155.201097  \n",
       "4          81.447482        3050.737         2966.249       66.966718  \n",
       "...              ...             ...              ...             ...  \n",
       "1018918          NaN        1437.405         1115.362             NaN  \n",
       "1018919          NaN        1156.722          771.364             NaN  \n",
       "1018920          NaN        6314.110         5986.291             NaN  \n",
       "1018921          NaN        2359.038          732.107             NaN  \n",
       "1018922          NaN        4468.388         4248.358             NaN  \n",
       "\n",
       "[1018923 rows x 14 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dohop_data['itinerary_fare'].fillna(dohop_data['booked_fare'], inplace=True)\n",
    "dohop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flights                       0\n",
       "origin                        0\n",
       "destination                   0\n",
       "cnx_airport                3587\n",
       "flight_time                   0\n",
       "connection_time               0\n",
       "dayofweek                     0\n",
       "bkgs_with_no_content          0\n",
       "pax                     1011761\n",
       "bookings                1011761\n",
       "booked_fare             1011761\n",
       "total_distance             4179\n",
       "direct_distance             592\n",
       "itinerary_fare           423158\n",
       "dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dohop_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_of_all_categories(raw_data, data_to_be_processed, column):\n",
    "    \"\"\"\n",
    "    This creates a list of all categories, and appends it to existing data that needs processing\n",
    "    it appends the data, processes it, and drops the unnecesary columns\n",
    "    It then appends it back to the dataframe so it can be used in the next step\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating dummy data\n",
    "    categories  = pd.DataFrame(raw_data[column].unique(), columns=[column])\n",
    "\n",
    "    # Merged data for encoding\n",
    "    merged_data = pd.concat([data_to_be_processed,categories])\n",
    "\n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_new_data(original_data, data_to_be_processed, column, encoder):\n",
    "    \"\"\"\n",
    "    This function allows for accurate encoding, that matches the training data\n",
    "    In order to do that, we need to give the encoder all the options it previously had, otherwise the binary encoding won't align\n",
    "    RETURNS: Only the encoded columns\n",
    "    \"\"\"\n",
    "    # Creating dummy data from the original data\n",
    "    data_with_dummies = create_df_of_all_categories(original_data, data_to_be_processed, column)\n",
    "\n",
    "    # Encoding the column\n",
    "    encoded_columns = encoder.transform(data_with_dummies[column])\n",
    "\n",
    "    # Removing dummy data\n",
    "    real_data = encoded_columns[:len(data_to_be_processed)].copy()\n",
    "\n",
    "    return real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_data(original_data, new_data, scalers, colums_to_keep,\n",
    "                     box_cox_columns=False, yeo_johnson_columns=False, log_transform_columns=False, min_max_columns=False,\n",
    "                     od_encoding=False, operator_encoding=False):\n",
    "    \"\"\"\n",
    "    This function processes new data, using scalers and encoders from the training set\n",
    "    It only returns the columns stated in columns_to_keep, and encoded columns if those options flipped to True\n",
    "    \"\"\"\n",
    "\n",
    "    # DATA CLEANING\n",
    "\n",
    "    # Filling the Null itinerary_fare data with booked_fare\n",
    "    new_data['itinerary_fare'].fillna(new_data['booked_fare'], inplace=True)\n",
    "\n",
    "    # Dropping data where itinerary_fare remains Null\n",
    "    clean_data = new_data.dropna(subset=['itinerary_fare'])\n",
    "\n",
    "    # FEATURE ENGINEERING\n",
    "    clean_data['DurationMin'] = clean_data['flight_time'] + clean_data['connection_time']\n",
    "\n",
    "    clean_data['total_layover_time'] = clean_data['DurationMin'] - clean_data['flight_time']\n",
    "    clean_data['total_layover_time_ratio'] = clean_data['connection_time'] / clean_data['DurationMin']\n",
    "\n",
    "    clean_data['extra_travel_distance'] = clean_data['total_distance'] - clean_data['direct_distance']\n",
    "    clean_data['extra_travel_distance_ratio'] =  clean_data['total_distance'] / clean_data['direct_distance']\n",
    "\n",
    "    # Renaming the columns\n",
    "    col_rename_dict = {'origin': 'OriginApt', 'destination':'DestinationApt', 'days_to_travel':'TravelHorizonDays', 'total_distance':'Total_Flight_Distance',\n",
    "                    'direct_distance':'TravelDistanceKm', 'connection_time':'total_layover_time', 'flight_time':'Total_Flight_Duration','itinerary_fare':'PricePerPax',\n",
    "                    'seg_0':'Seg_0_OperatingCarrierIATA', 'seg_1':'Seg_1_OperatingCarrierIATA', 'seg_2':'Seg_2_OperatingCarrierIATA', 'seg_3':'Seg_3_OperatingCarrierIATA'}\n",
    "\n",
    "    clean_data = clean_data.rename(columns=col_rename_dict).copy()\n",
    "\n",
    "    #TEMP creating Stops and SelfTransfer data\n",
    "    clean_data['Stops'] = 1\n",
    "    clean_data['SelfTransfer'] = True\n",
    "\n",
    "    #DATA CLEANING\n",
    "    for column in clean_data.select_dtypes(include=['int64']).columns:\n",
    "        clean_data[column] = clean_data[column].astype('float64')\n",
    "\n",
    "    # ENCODING\n",
    "    if od_encoding:\n",
    "        #Binary encoding origin\n",
    "        origin_encoded = encoding_new_data(original_data=original_data, data_to_be_processed=clean_data, column='OriginApt', encoder=scalers.o_encoder)\n",
    "\n",
    "        # Binary encoding Destination\n",
    "        destination_encoded = encoding_new_data(original_data, clean_data, 'DestinationApt', scalers.d_encoder)\n",
    "\n",
    "        # Updating the dataset with the encoded columns\n",
    "        clean_data = pd.concat([clean_data, origin_encoded, destination_encoded], axis=1)\n",
    "\n",
    "        # Ensuring the columns are returned at the end of the function\n",
    "        colums_to_keep.extend(origin_encoded.columns.to_list())\n",
    "        colums_to_keep.extend(destination_encoded.columns.to_list())\n",
    "\n",
    "    if operator_encoding:\n",
    "        seg_0_op_iata = encoding_new_data(original_data, clean_data, 'Seg_0_OperatingCarrierIATA', scalers.seg_0_encoder)\n",
    "        seg_1_op_iata = encoding_new_data(original_data, clean_data, 'Seg_1_OperatingCarrierIATA', scalers.seg_1_encoder)\n",
    "        seg_2_op_iata = encoding_new_data(original_data, clean_data, 'Seg_2_OperatingCarrierIATA', scalers.seg_2_encoder)\n",
    "        seg_3_op_iata = encoding_new_data(original_data, clean_data, 'Seg_3_OperatingCarrierIATA', scalers.seg_3_encoder)\n",
    "\n",
    "        # Updating the dataset with the encoded columns\n",
    "        clean_data = pd.concat([clean_data, seg_0_op_iata, seg_1_op_iata, seg_2_op_iata, seg_3_op_iata], axis=1)\n",
    "\n",
    "        # Ensuring the columns are returned at the end of the function\n",
    "        colums_to_keep.extend(seg_0_op_iata.columns.to_list())\n",
    "        colums_to_keep.extend(seg_1_op_iata.columns.to_list())\n",
    "        colums_to_keep.extend(seg_2_op_iata.columns.to_list())\n",
    "        colums_to_keep.extend(seg_3_op_iata.columns.to_list())\n",
    "\n",
    "\n",
    "    # SCALING\n",
    "    # Box cox\n",
    "    if box_cox_columns:\n",
    "        for col in box_cox_columns:\n",
    "            clean_data.loc[:,col]  = stats.boxcox(clean_data[col], lmbda=scalers.box_lambda[col])\n",
    "\n",
    "    # Yeo-johnson\n",
    "    if yeo_johnson_columns:\n",
    "        for col in yeo_johnson_columns:\n",
    "            clean_data.loc[:,col] = stats.yeojohnson(clean_data[col], lmbda=scalers.yeo_lambda[col])\n",
    "\n",
    "    # Log transformations\n",
    "    if log_transform_columns:\n",
    "        for col in log_transform_columns:\n",
    "            clean_data.loc[:,col] = np.log1p(clean_data[col])\n",
    "\n",
    "    #Min max scaling\n",
    "    if min_max_columns:\n",
    "        for col in min_max_columns:\n",
    "            clean_data.loc[:,col] = scalers.minmax_scaler[col].transform(clean_data[[col]])\n",
    "\n",
    "    if 'SelfTransfer' in colums_to_keep:\n",
    "        #Inversing the importance of SelfTransfer, so Non Self Transfer is seen as better by the model\n",
    "        clean_data['SelfTransfer'] = clean_data['SelfTransfer'].apply(convert_bool_to_num)\n",
    "\n",
    "    data_to_return = clean_data[colums_to_keep].copy()\n",
    "\n",
    "    if 'dayofweek' in colums_to_keep:\n",
    "        # Cyclical encoding\n",
    "        data_to_return['sin_day'] = np.sin(2 * np.pi * data_to_return['dayofweek'] / 7)\n",
    "        data_to_return['cos_day'] = np.cos(2 * np.pi * data_to_return['dayofweek'] / 7)\n",
    "\n",
    "        # Dropping day of week as it is no longer neccesary\n",
    "        data_to_return = data_to_return.drop(columns=['dayofweek']).copy()\n",
    "\n",
    "    return data_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/62/d7t21rj54ls65fhypjm4ryb00000gn/T/ipykernel_40434/415612424.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['DurationMin'] = clean_data['flight_time'] + clean_data['connection_time']\n",
      "/var/folders/62/d7t21rj54ls65fhypjm4ryb00000gn/T/ipykernel_40434/415612424.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['total_layover_time'] = clean_data['DurationMin'] - clean_data['flight_time']\n",
      "/var/folders/62/d7t21rj54ls65fhypjm4ryb00000gn/T/ipykernel_40434/415612424.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['total_layover_time_ratio'] = clean_data['connection_time'] / clean_data['DurationMin']\n",
      "/var/folders/62/d7t21rj54ls65fhypjm4ryb00000gn/T/ipykernel_40434/415612424.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['extra_travel_distance'] = clean_data['total_distance'] - clean_data['direct_distance']\n",
      "/var/folders/62/d7t21rj54ls65fhypjm4ryb00000gn/T/ipykernel_40434/415612424.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_data['extra_travel_distance_ratio'] =  clean_data['total_distance'] / clean_data['direct_distance']\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[366], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_new_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmaller_raw_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdohop_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_max_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_max_scaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_transform_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_transorm_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mod_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[365], line 44\u001b[0m, in \u001b[0;36mprocess_new_data\u001b[0;34m(original_data, new_data, scalers, colums_to_keep, box_cox_columns, yeo_johnson_columns, log_transform_columns, min_max_columns, od_encoding, operator_encoding)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ENCODING\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m od_encoding:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#Binary encoding origin\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     origin_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mencoding_new_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_to_be_processed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOriginApt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Binary encoding Destination\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     destination_encoded \u001b[38;5;241m=\u001b[39m encoding_new_data(original_data, clean_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDestinationApt\u001b[39m\u001b[38;5;124m'\u001b[39m, scalers\u001b[38;5;241m.\u001b[39md_encoder)\n",
      "Cell \u001b[0;32mIn[360], line 8\u001b[0m, in \u001b[0;36mencoding_new_data\u001b[0;34m(original_data, data_to_be_processed, column, encoder)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis function allows for accurate encoding, that matches the training data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mIn order to do that, we need to give the encoder all the options it previously had, otherwise the binary encoding won't align\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mRETURNS: Only the encoded columns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Creating dummy data from the original data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m data_with_dummies \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_df_of_all_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_to_be_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Encoding the column\u001b[39;00m\n\u001b[1;32m     11\u001b[0m encoded_columns \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(data_with_dummies[column])\n",
      "Cell \u001b[0;32mIn[359], line 12\u001b[0m, in \u001b[0;36mcreate_df_of_all_categories\u001b[0;34m(raw_data, data_to_be_processed, column)\u001b[0m\n\u001b[1;32m      9\u001b[0m categories  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(raw_data[column]\u001b[38;5;241m.\u001b[39munique(), columns\u001b[38;5;241m=\u001b[39m[column])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Merged data for encoding\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_to_be_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/envs/OptiEnv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/envs/OptiEnv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:676\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    675\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 676\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    680\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    681\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    682\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/envs/OptiEnv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3874\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3871\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3874\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "process_new_data(smaller_raw_data, dohop_data, scal, columns, min_max_columns=min_max_scaling, log_transform_columns=log_transorm_cols, od_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING\n",
    "\n",
    "# Filling the Null itinerary_fare data with booked_fare\n",
    "dohop_data['itinerary_fare'].fillna(dohop_data['booked_fare'], inplace=True)\n",
    "\n",
    "# Dropping data where itinerary_fare remains Null\n",
    "clean_data = dohop_data.dropna(subset=['itinerary_fare']).copy()\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "clean_data['DurationMin'] = clean_data['flight_time'] + clean_data['connection_time']\n",
    "\n",
    "clean_data['total_layover_time'] = clean_data['DurationMin'] - clean_data['flight_time']\n",
    "clean_data['total_layover_time_ratio'] = clean_data['connection_time'] / clean_data['DurationMin']\n",
    "\n",
    "clean_data['extra_travel_distance'] = clean_data['total_distance'] - clean_data['direct_distance']\n",
    "clean_data['extra_travel_distance_ratio'] =  clean_data['total_distance'] / clean_data['direct_distance']\n",
    "\n",
    "# Renaming the columns\n",
    "col_rename_dict = {'origin': 'OriginApt', 'destination':'DestinationApt', 'days_to_travel':'TravelHorizonDays', 'total_distance':'Total_Flight_Distance',\n",
    "                'direct_distance':'TravelDistanceKm', 'connection_time':'total_layover_time', 'flight_time':'Total_Flight_Duration','itinerary_fare':'PricePerPax',\n",
    "                'seg_0':'Seg_0_OperatingCarrierIATA', 'seg_1':'Seg_1_OperatingCarrierIATA', 'seg_2':'Seg_2_OperatingCarrierIATA', 'seg_3':'Seg_3_OperatingCarrierIATA'}\n",
    "\n",
    "clean_data = clean_data.rename(columns=col_rename_dict)\n",
    "\n",
    "#TEMP creating Stops and SelfTransfer data\n",
    "clean_data['Stops'] = 1\n",
    "clean_data['SelfTransfer'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[379], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mencoding_new_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmaller_raw_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSeg_0_OperatingCarrierIATA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseg_0_encoder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[360], line 8\u001b[0m, in \u001b[0;36mencoding_new_data\u001b[0;34m(original_data, data_to_be_processed, column, encoder)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mThis function allows for accurate encoding, that matches the training data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mIn order to do that, we need to give the encoder all the options it previously had, otherwise the binary encoding won't align\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mRETURNS: Only the encoded columns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Creating dummy data from the original data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m data_with_dummies \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_df_of_all_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_to_be_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Encoding the column\u001b[39;00m\n\u001b[1;32m     11\u001b[0m encoded_columns \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(data_with_dummies[column])\n",
      "Cell \u001b[0;32mIn[359], line 12\u001b[0m, in \u001b[0;36mcreate_df_of_all_categories\u001b[0;34m(raw_data, data_to_be_processed, column)\u001b[0m\n\u001b[1;32m      9\u001b[0m categories  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(raw_data[column]\u001b[38;5;241m.\u001b[39munique(), columns\u001b[38;5;241m=\u001b[39m[column])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Merged data for encoding\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_to_be_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merged_data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/envs/OptiEnv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/envs/OptiEnv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:676\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[1;32m    675\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[0;32m--> 676\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m \u001b[43mobj_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m    680\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    681\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    682\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/envs/OptiEnv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3874\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3871\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[1;32m   3873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 3874\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[1;32m   3876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "encoding_new_data(smaller_raw_data, clean_data, 'Seg_0_OperatingCarrierIATA', scal.seg_0_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OptiEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
